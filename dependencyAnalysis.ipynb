{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/core/errors.py:160: UserWarning: unable to install sys.excepthook to format Scenic backtraces\n",
      "  warnings.warn('unable to install sys.excepthook to format Scenic backtraces')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "Done loading in 37.120 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 9.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import scenic\n",
    "\n",
    "### NuScenes Query\n",
    "from scenic.simulators.carla.nusc_query_api import NuscQueryAPI\n",
    "nusc = NuscQueryAPI(version='v1.0-trainval', \\\n",
    "                    dataroot='/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scenic\n",
    "\n",
    "### NuScenes Query\n",
    "# from scenic.simulators.carla.nusc_query_api import NuscQueryAPI\n",
    "# nusc = NuscQueryAPI(version='v1.0-trainval', \\\n",
    "#                     dataroot='/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scenic\n",
    "from scenic.core.regions import SectorRegion, CircularRegion\n",
    "from scenic.core.vectors import OrientedVector, Vector\n",
    "from scenic.core.distributions import Samplable, writeSMTtoFile, smt_lessThanEq, smt_and, smt_add, smt_subtract, smt_assert\n",
    "from scenic.domains.driving.roads import Network\n",
    "from scenic.core.regions import PointInRegionDistribution\n",
    "from scenic.core.type_support import TypecheckedDistribution\n",
    "from scenic.core.geometry import normalizeAngle\n",
    "import subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "### Dependency Analysis\n",
    "def cacheExprTreeNodes(attribute, nodeSet=None):\n",
    "    \"\"\"cache all the nodes of the input attribute's expression tree to the dictionary\"\"\"\n",
    "    if nodeSet is None:\n",
    "        nodeSet = set()\n",
    "    nodeSet.add(attribute)\n",
    "    if not isinstance(attribute, Samplable) or attribute._dependencies == ():\n",
    "        return nodeSet\n",
    "    for dep in attribute._dependencies:\n",
    "        cacheExprTreeNodes(dep, nodeSet)\n",
    "    return nodeSet\n",
    "\n",
    "def cacheAttributes(scenario, attributeList):\n",
    "    dictionary = {}\n",
    "    dictionary['objAttributes_names'] = []\n",
    "    dictionary['positionAttributes_names'] = []\n",
    "    dictionary['headingAttributes_names'] = []\n",
    "    \n",
    "    # cache all object attributes\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[i]\n",
    "        obj_name = 'obj'+str(i)\n",
    "        dictionary[obj_name] = {}\n",
    "        \n",
    "        for attribute in attributeList:\n",
    "            dictionary[obj_name][attribute] = {}\n",
    "            dictionary[obj_name][attribute]['self'] = getattr(obj, attribute)\n",
    "            dictionary[obj_name][attribute]['set'] = cacheExprTreeNodes(getattr(obj, attribute), None)\n",
    "            dictionary[obj_name][attribute]['intermediate_variables_set'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attributes_objs'] = set()\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attributes_objs'] = set()\n",
    "            dictionary['objAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'position':\n",
    "                dictionary['positionAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'heading':\n",
    "                dictionary['headingAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "                \n",
    "    return dictionary\n",
    "\n",
    "def checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "    \"\"\" checks whether the two attr1 and attr2 are jointly dependent on an intermediate variable\n",
    "    or is both dependent on another attribute. \n",
    "    Output:\n",
    "    True, if attr1 and attr2 are \"dependent\" on another attribute, not intermediate variable\n",
    "    False, attr1 and attr2 are both \"jointly dependent\" on an intermediate variable\n",
    "    \"\"\"\n",
    "    [obj1_name, attr1] = attr1_name.split('_')\n",
    "    attr1_obj = dictionary[obj1_name][attr1]['self']\n",
    "    attr1_jointly_dep_attr_names = dictionary[obj1_name][attr1]['jointly_dependent_attribute_names']\n",
    "    [obj2_name, attr2] = attr2_name.split('_')\n",
    "    attr2_obj = dictionary[obj2_name][attr2]['self']\n",
    "    attr2_jointly_dep_attr_names = dictionary[obj2_name][attr2]['jointly_dependent_attribute_names']\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr1_name: \", attr1_name)\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr2_name: \", attr2_name)\n",
    "    original_intersection = intersection\n",
    "    \n",
    "    objAttributes_names = dictionary['objAttributes_names'] \n",
    "    for attr_name in objAttributes_names:\n",
    "        if attr_name == attr1_name:\n",
    "            continue\n",
    "        elif attr_name == attr2_name:\n",
    "            break\n",
    "        else:\n",
    "            [obj_name, attr] = attr_name.split('_')\n",
    "            attr_obj = dictionary[obj_name][attr]['self']\n",
    "            attr_depSet = dictionary[obj_name][attr]['dependent_attribute_names']\n",
    "            \n",
    "            if attr_obj in original_intersection and attr_name not in attr1_jointly_dep_attr_names \\\n",
    "                and attr_name not in attr2_jointly_dep_attr_names: \n",
    "#                 print(\"other attr_name in the intersection: \", attr_name)\n",
    "                attr_cachedSet = dictionary[obj_name][attr]['set']\n",
    "                original_intersection = original_intersection - attr_cachedSet\n",
    "#                 print(\"len(original_intersection): \", len(original_intersection))\n",
    "                if len(original_intersection) == 0:\n",
    "#                     print(\"returns True\")\n",
    "                    # the intersection is another attribute\n",
    "                    return True\n",
    "    return False\n",
    "        \n",
    "def findAttribute(other_attr_obj, attr_dict, dictionary):\n",
    "    for obj_attr in attr_dict['dependent_attribute_names']:\n",
    "        [obj, attr] = obj_attr.split(\"_\")\n",
    "        if other_attr_obj is dictionary[obj][attr]['self']:\n",
    "            return obj_attr\n",
    "    return None\n",
    "\n",
    "def checkIntermediateSetMembership(attr_obj, attrIntermediateList):\n",
    "    for intermediateSet in attrIntermediateList:\n",
    "        if attr_obj in intermediateSet:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def analysis(objAttributes_names, dictionary):\n",
    "    for i in range(len(objAttributes_names)):\n",
    "        for j in range(len(objAttributes_names)):\n",
    "            if i < j:\n",
    "                attr1_name = objAttributes_names[i]\n",
    "                attr2_name = objAttributes_names[j]\n",
    "                [obj_name1, attr1] = attr1_name.split('_')\n",
    "                [obj_name2, attr2] = attr2_name.split('_')\n",
    "        \n",
    "                attribute1 = dictionary[obj_name1][attr1]\n",
    "                attribute2 = dictionary[obj_name2][attr2]\n",
    "                attr1_obj = attribute1['self']\n",
    "                attr2_obj = attribute2['self']\n",
    "                \n",
    "                set1 = attribute1['set']\n",
    "                set2 = attribute2['set']\n",
    "                intersection = set1.intersection(set2)\n",
    "                \n",
    "                if attr1_obj in intersection and attr1_obj not in attribute2['dependent_attributes_objs']:\n",
    "                    # attr2_obj is dependent on attr1_obj\n",
    "                    attribute2['dependent_attribute_names'].append(attr1_name)\n",
    "                    attribute2['dependent_attributes_objs'].add(attr1_obj)\n",
    "                elif attr2_obj in intersection and attr2_obj not in attribute1['dependent_attributes_objs']:\n",
    "                    # jointly_dependent case (e.g. depedendencyAnalysisTest4.scenic)\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "                        \n",
    "                elif len(intersection) > 0 \\\n",
    "                    and attr1_obj not in intersection and attr2_obj not in intersection \\\n",
    "                    and not checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "                    # the two attributes are jointly dependent (i.e. share intermediate variable(s))\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "                    \n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    return dictionary\n",
    "    \n",
    "def dependencyAnalysis(scenario, attributeList):\n",
    "    dictionary = cacheAttributes(scenario, attributeList)\n",
    "    dictionary['numberOfObjects'] = len(scenario.original_objects)\n",
    "    objAttributes_names = dictionary['objAttributes_names']\n",
    "    dictionary = analysis(objAttributes_names, dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def sortDependency(dictionary, scenario, monolithic_translation=False):\n",
    "    output = []\n",
    "    covered_attributes = []\n",
    "    \n",
    "    if not monolithic_translation:\n",
    "        for elem in dictionary['objAttributes_names']:\n",
    "            if elem in covered_attributes:\n",
    "                continue\n",
    "            covered_attributes.append(elem)\n",
    "            [obj_name, attr_name] = elem.split(\"_\")\n",
    "            joint_dep_set = dictionary[obj_name][attr_name]['jointly_dependent_attribute_names']\n",
    "            if len(joint_dep_set) > 0:\n",
    "                jointly_dependent_list = [elem]\n",
    "\n",
    "                for j in joint_dep_set:\n",
    "                    [j_obj_name, j_attr] = j.split(\"_\")\n",
    "                    if j not in covered_attributes:\n",
    "                        jointly_dependent_list.append(j)\n",
    "                        covered_attributes.append(j)\n",
    "                output.append(jointly_dependent_list)\n",
    "            else:\n",
    "                output.append([elem])\n",
    "    else:\n",
    "        output = [(dictionary['objAttributes_names'])]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Test Dependency Analysis\n",
    "# scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/parkedCar.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "\n",
    "# attributeList = ['position', 'heading']\n",
    "# d = dependencyAnalysis(scenario, attributeList)\n",
    "# print(sortDependency(d, scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = cacheAttributes(scenario, attributeList)\n",
    "# obj1_pos = dictionary['obj1']['position']['set']\n",
    "# obj2_pos = dictionary['obj2']['position']['set']\n",
    "# intersection = list(obj1_pos.intersection(obj2_pos))\n",
    "# print(intersection[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### SMT Translation Pipeline\n",
    "\n",
    "def resetConditionedVar(obj):\n",
    "    if not isinstance(obj, Samplable):\n",
    "        return None\n",
    "    obj._conditioned = obj\n",
    "    if (obj._dependencies is None):\n",
    "        return None\n",
    "    for dep in obj._dependencies:\n",
    "        resetConditionedVar(dep)\n",
    "    return None\n",
    "\n",
    "def unconditionAllAttributes(scenario):\n",
    "    for obj in scenario.objects:\n",
    "        resetConditionedVar(obj.position)\n",
    "        resetConditionedVar(obj.heading)\n",
    "        \n",
    "def extractLabelAttribute(label, obj_index, attribute_name, objType, dataType, correspondence, egoObjIndex):\n",
    "    # Extract specific attribute from a label generated from a scenic program\n",
    "    \n",
    "#     print(\"extractLabelAttribute()\")\n",
    "#     print(\"label[objType]: \", label[objType])\n",
    "#     print(\"correspondence: \", correspondence)\n",
    "#     print(\"correspondence[obj_index]: \", correspondence[obj_index])\n",
    "#     print(\"attribute_name: \", attribute_name)\n",
    "#     print(\"obj_index: \", obj_index)\n",
    "#     print(\"egoObjIndex: \", egoObjIndex)\n",
    "    output = None\n",
    "    if obj_index != egoObjIndex:\n",
    "        if obj_index > egoObjIndex:\n",
    "            output = label[objType][correspondence[obj_index-1]][attribute_name]\n",
    "    else:\n",
    "        output = label['EgoCar'][attribute_name]\n",
    "\n",
    "    assert(output is not None)\n",
    "    if attribute_name == 'position':\n",
    "        return Vector(output[0], output[1])\n",
    "    if dataType == 'nuScenes':\n",
    "        output = normalizeAngle(math.radians(output-90)) #90 deg to reorient to Scenic's global coordinate system\n",
    "    return output\n",
    "        \n",
    "def initializeSMTFile(smt_file_path):\n",
    "    if os.path.isfile(smt_file_path):\n",
    "        os.remove(smt_file_path)\n",
    "    \n",
    "    open(smt_file_path, 'w').close()\n",
    "    writeSMTtoFile(smt_file_path, '(set-logic QF_NRA)')\n",
    "    \n",
    "def resetDictionary(cached_variables, smt_file_path):\n",
    "    regionAroundEgo = cached_variables['regionAroundEgo']\n",
    "    cached_variables.clear()\n",
    "    cached_variables['variables'] = []\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    \n",
    "def isFloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                   dictionary, errorBound, debug=False):\n",
    "    \n",
    "    x_error_margin = str(errorBound['x'])\n",
    "    y_error_margin = str(errorBound['y'])\n",
    "    heading_error_margin = errorBound['heading']\n",
    "    \n",
    "    ## TODO: add error bound range to attributes\n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    obj_name, attr_type = attribute_name.split(\"_\")\n",
    "\n",
    "    # Encode the given attribute's expression tree\n",
    "    smt_var = attr_obj.encodeToSMT(smt_file_path, cached_variables, debug = debug)\n",
    "    if smt_var is None:\n",
    "        return False\n",
    "    \n",
    "    if attr_type == 'position':\n",
    "        assert(isinstance(attr_label, Vector))\n",
    "        x, y = smt_var\n",
    "        (x_label, y_label) = (str(attr_label.x), str(attr_label.y))\n",
    "        x_cond1 = smt_lessThanEq(smt_subtract(x_label, x_error_margin), x)\n",
    "        x_cond2 = smt_lessThanEq(x, smt_add(x_label, x_error_margin))\n",
    "        x_cond = smt_and(x_cond1, x_cond2)\n",
    "        \n",
    "        y_cond1 = smt_lessThanEq(smt_subtract(y_label, y_error_margin), y)\n",
    "        y_cond2 = smt_lessThanEq(y, smt_add(y_label, y_error_margin))\n",
    "        y_cond = smt_and(y_cond1, y_cond2)\n",
    "        \n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, smt_and(x_cond, y_cond)))\n",
    "    else:\n",
    "        heading_label = str(attr_label)\n",
    "        \n",
    "        # normalize heading\n",
    "        norm_var = findVariableName(smt_file_path, cached_variables, 'normalized', debug=debug)\n",
    "        if not isinstance(isFloat(smt_var), float):\n",
    "            normalize1 = smt_assert(\"equal\", norm_var, smt_ite(smt_lessThanEq(\"3.1416\", smt_var), \\\n",
    "                                                        smt_subtract(smt_var,\"6.2832\"), \\\n",
    "                                                        smt_ite(smt_lessThanEq(smt_var, \"-3.1416\"), \\\n",
    "                                                        smt_add(smt_var,\"6.2832\"), smt_var)))\n",
    "            writeSMTtoFile(smt_file_path, normalize1)\n",
    "\n",
    "        else:\n",
    "            smt_var_float = isFloat(smt_var)\n",
    "            if 3.1416 < smt_var_float:\n",
    "                normalize1 = smt_assert(\"equal\", norm_var, str(smt_var_float-6.2832))\n",
    "            elif smt_var_float < -3.1416:\n",
    "                normalize1 = smt_assert(\"equal\", norm_var, str(6.2832-smt_var_float))\n",
    "            else:\n",
    "                normalize1 = smt_assert(\"equal\", norm_var, smt_var)\n",
    "            writeSMTtoFile(smt_file_path, normalize1)\n",
    "            \n",
    "        # check heading within [-pi, pi] interval\n",
    "        heading_cond1 = smt_lessThanEq(smt_subtract(heading_label, str(heading_error_margin)), norm_var)\n",
    "        heading_cond2 = smt_lessThanEq(norm_var, smt_add(heading_label, str(heading_error_margin)))\n",
    "        heading1 = smt_and(heading_cond1, heading_cond2)\n",
    "        \n",
    "        # check heading at wrap around case\n",
    "        if attr_label > 0:\n",
    "            smt_var2 = smt_add(smt_subtract(str(3.1416), str(heading_label)), smt_subtract(norm_var, str(-3.1416)))\n",
    "        else:\n",
    "            smt_var2 = smt_add(smt_subtract(str(heading_label), str(-3.1416)), smt_subtract(str(3.1416), norm_var))\n",
    "        heading_cond1 = smt_lessThanEq(str(-heading_error_margin), smt_var2)\n",
    "        heading_cond2 = smt_lessThanEq(smt_var2, str(heading_error_margin))\n",
    "        heading2 = smt_and(heading_cond1, heading_cond2)\n",
    "        \n",
    "        heading = smt_or(heading1, heading2)            \n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, heading))\n",
    "#         writeSMTtoFile(smt_file_path, smt_assert(None, smt_equal(str(attr_label), smt_var)))\n",
    "    return True\n",
    "        \n",
    "def findObjType(obj):\n",
    "    if \"Car\" in str(obj) or \"Truck\" in str(obj) or \"Motorcycle\" in str(obj) or \"Bicycle\" in str(obj):\n",
    "        return \"Vehicles\"\n",
    "    elif \"Pedestrian\" in str(obj):\n",
    "        return \"Pedestrians\"\n",
    "    elif \"Cone\" in str(obj) or \"Trash\" in str(obj):\n",
    "        return \"Objects\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return None\n",
    "\n",
    "def conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, correspondence, \\\n",
    "                        egoObjIndex, label):\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence, \\\n",
    "                                              egoObjIndex)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "#         print(\"conditionAttributes attribute: \", attribute_name)\n",
    "#         print(\"conditionAttributes attr_label: \", attr_label)\n",
    "        if isinstance(attr_label, float) or isinstance(attr_label, int):\n",
    "            attr_obj.conditionTo(Constant(attr_label))\n",
    "        elif isinstance(attr_obj, PointInRegionDistribution):\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "            if isinstance(attr_obj.region, TypecheckedDistribution): \n",
    "                attr_obj.region.dist.conditionTo(attr_label)\n",
    "            else:\n",
    "                attr_obj.region.conditionTo(attr_label)\n",
    "        else:\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "\n",
    "def validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                         correspondence, egoObjIndex, dataType, errorBound, debug=False, falseTesting=False,\\\n",
    "                        monolithic_translation=False):\n",
    "    \n",
    "    count = 0\n",
    "    ## translate jointly dependent attribute expression trees\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence,\\\n",
    "                                          egoObjIndex)\n",
    "#         print(\"validateLabelElement() attribute_name: \", attribute_name)\n",
    "#         print(\"attr_label: \", attr_label)\n",
    "#         print(\"correspondence: \", correspondence)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "        translated = translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                          dictionary, errorBound, debug)\n",
    "        if not translated:\n",
    "#             print(\"TRANSLATION FAILED: NONE RETURNED\")\n",
    "            return False\n",
    "#         print(\"validateLabelElement encoding done for validateLabelElement: \", attribute_name)\n",
    "#         if monolithic_translation:\n",
    "#             print(\"validLabelElement: Monolithic translation case -- condition attribute: \",attribute_name)\n",
    "#             conditionAttributes([attribute_name], dictionary, scenario, dataType, correspondence, \\\n",
    "#                         egoObjIndex, label)\n",
    "    \n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    writeSMTtoFile(smt_file_path, \"(check-sat)\")\n",
    "    writeSMTtoFile(smt_file_path, \"(exit)\")\n",
    "\n",
    "    if subprocess.call(\"./run_smt_encoding.sh\") == 1:\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def createCorrespondence(correspondence, objType, objTypeOrder, objTypeCorrespondence):\n",
    "    index = 0\n",
    "    correspond_copy = correspondence.copy()\n",
    "    for i in range(len(objTypeOrder)):\n",
    "        if objTypeOrder[i] == objType:\n",
    "            correspond_copy[i] = objTypeCorrespondence[index]\n",
    "            index += 1\n",
    "            if index == len(objTypeCorrespondence):\n",
    "                break\n",
    "    return correspond_copy\n",
    "    \n",
    "\n",
    "def findEgoObjIndex(scenario):\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        if scenario.original_objects[i] is scenario.egoObject:\n",
    "            return i\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinePermutation(permutation_list, num_elem):\n",
    "    refined_list = set()\n",
    "    for perm in permutation_list:\n",
    "        refined_list.add(tuple(list(perm)[:num_elem]))\n",
    "    output = list(refined_list)\n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "def generateObjectMatchingCorrespondenceSet(scenario, label):\n",
    "    objTypeOrder = []\n",
    "    objTypeDict = {}\n",
    "    \n",
    "    # Count the number of objType in the Scenic program and the label\n",
    "    for obj in scenario.original_objects:\n",
    "        if obj is not scenario.egoObject:\n",
    "            objType = findObjType(obj)\n",
    "            objTypeOrder.append(objType)\n",
    "            \n",
    "            if objType not in objTypeDict.keys():\n",
    "                objTypeDict[objType] = {}\n",
    "                objTypeDict[objType]['label_count'] = len(label[objType])\n",
    "                objTypeDict[objType]['scenic_count'] = 1\n",
    "            else:\n",
    "                objTypeDict[objType]['scenic_count'] += 1\n",
    "    \n",
    "#     print(\"objTypeOrder: \", objTypeOrder)\n",
    "    \n",
    "    # \n",
    "    total_permutation_number = 1\n",
    "    for objType in objTypeDict.keys():\n",
    "        label_count = objTypeDict[objType]['label_count']\n",
    "        scenic_count= objTypeDict[objType]['scenic_count']\n",
    "        assert(label_count >= scenic_count)\n",
    "        \n",
    "        index_list = [i for i in range(label_count)]\n",
    "        permutation_list = list(itertools.permutations(index_list))\n",
    "        objTypeDict[objType]['correspondence'] = refinePermutation(permutation_list, scenic_count)\n",
    "        total_permutation_number *= int(math.factorial(label_count) / math.factorial(label_count - scenic_count))\n",
    "    \n",
    "#     print(\"total_permutation_number: \", total_permutation_number)\n",
    "#     for objType in objTypeDict.keys():\n",
    "#         print(\"objType: \", objType)\n",
    "#         print(\"objType scenic_count: \", objTypeDict[objType]['scenic_count'])\n",
    "#         print(\"objType label_count: \", objTypeDict[objType]['label_count'])\n",
    "#         print(\"objType Correspondence: \", objTypeDict[objType]['correspondence'])\n",
    "#         print(\"len(correspondence): \", len(objTypeDict[objType]['correspondence']))\n",
    "#     print(\"objTypeDict['Vehicles']['scenic_count']: \", objTypeDict['Vehicles']['scenic_count'])\n",
    "#     print(\"objTypeDict['Vehicles']['label_count']: \", objTypeDict['Vehicles']['label_count'])\n",
    "#     print(\"objTypeDict['Vehicles']['correspondence']: \", objTypeDict['Vehicles']['correspondence'])\n",
    "#     print(\"len(objTypeDict['Vehicles']['correspondence']): \", len(objTypeDict['Vehicles']['correspondence']))\n",
    "#     print(\"objTypeDict['Pedestrians']['scenic_count']\", objTypeDict['Pedestrians']['scenic_count'])\n",
    "#     print(\"objTypeDict['Pedestrians']['label_count']\", objTypeDict['Pedestrians']['label_count'])\n",
    "#     print(\"objTypeDict['Pedestrians']['correspondence']\", objTypeDict['Pedestrians']['correspondence'])\n",
    "#     print(\"objTypeDict['Objects']['count']\", objTypeDict['Objects']['count'])\n",
    "#     print(\"objTypeDict['Objects']['correspondence']\", objTypeDict['Objects']['correspondence'])\n",
    "    \n",
    "    # sort the types by the number of counts\n",
    "    types = list(objTypeDict.keys())\n",
    "    counts = [len(objTypeDict[objType]['correspondence']) for objType in types]\n",
    "    sorted_types = []\n",
    "    sorted_types_nums = []\n",
    "    \n",
    "    for i in range(len(types)):\n",
    "        elem = max(counts)\n",
    "        index = counts.index(max(counts))\n",
    "        sorted_types.append(types[index])\n",
    "        sorted_types_nums.append(elem)\n",
    "        del types[index]\n",
    "        del counts[index]\n",
    "    \n",
    "#     print(\"sorted_types: \", sorted_types)\n",
    "#     print(\"sorted_types_nums: \", sorted_types_nums)\n",
    "    \n",
    "    if len(objTypeOrder)==0:\n",
    "        return [(0,)]\n",
    "    \n",
    "    # compute the number of identical elements to insert per objType\n",
    "    num_identicals = []\n",
    "    for i in range(len(sorted_types)):\n",
    "        if i == len(sorted_types)-1:\n",
    "            num_identicals.append(1)\n",
    "        else:\n",
    "            num_identicals.append(np.prod(sorted_types_nums[i+1:]))\n",
    "#     print(\"num_identicals: \", num_identicals)\n",
    "    \n",
    "    # create combinations of correspondences in the order of objTypeOrder\n",
    "#     print(\"total_permutation_number: \", total_permutation_number)\n",
    "    correspondenceList = [[0]*len(objTypeOrder) for i in range(total_permutation_number)]\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "\n",
    "    # Handling first objType\n",
    "    objType = sorted_types[0]\n",
    "    for j in range(len(objTypeDict[objType]['correspondence'])):\n",
    "        correspondenceToEdit = correspondenceList[index]\n",
    "#         print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "        objTypeCorrespondence = objTypeDict[objType]['correspondence'][j]\n",
    "#         print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "        correspondence = createCorrespondence(correspondenceToEdit, objType, objTypeOrder, \\\n",
    "                                              objTypeCorrespondence)\n",
    "#         print(\"correspondence: \", correspondence)\n",
    "\n",
    "        for k in range(num_identicals[0]):\n",
    "            correspondenceList[index] = correspondence\n",
    "            index += 1\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "#     print(\"len(correspondenceList): \", len(correspondenceList))\n",
    "#     print(\"correspondenceList is Valid: \", len(correspondenceList)/num_identicals[0]==\\\n",
    "#           len(set([tuple(elem) for elem in correspondenceList])))\n",
    "    \n",
    "    # Handle the rest of objType \n",
    "    for i in range(1,len(sorted_types)):\n",
    "    # for each remaining object\n",
    "        index = 0\n",
    "        objType = sorted_types[i]\n",
    "#         print(\"processing objType: \", objType)\n",
    "        for j in range(len(objTypeDict[sorted_types[0]]['correspondence'])): \n",
    "        # loop for the number of first objType's correspondence\n",
    "            for k in range(len(objTypeDict[objType]['correspondence'])):\n",
    "            # loop for the number of distinct correspondences of remaining per obj\n",
    "                correspondenceToEdit = correspondenceList[index]\n",
    "#                 print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "                objTypeCorrespondence = objTypeDict[objType]['correspondence'][k]\n",
    "#                 print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "                correspondence = createCorrespondence(correspondenceToEdit, objType, \\\n",
    "                                objTypeOrder, objTypeCorrespondence)\n",
    "#                 print(\"correspondence: \", correspondence)\n",
    "                for l in range(num_identicals[i]):\n",
    "                    correspondenceList[index] = correspondence\n",
    "                    index += 1\n",
    "#                     print(\"index: \", index)\n",
    "                \n",
    "#                 print(\"kth loop completed: \", k)\n",
    "#             print(\"jth full loop completed: \", j)\n",
    "\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "    \n",
    "    return correspondenceList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/8_agent_scenario.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# x = generateObjectMatchingCorrespondenceSet(scenario)\n",
    "# print(\"finalOutput: \", x)\n",
    "# print(len(x))\n",
    "# print(len(set([tuple(elem) for elem in x])))\n",
    "\n",
    "# label = {}\n",
    "# label['Vehicles'] = [0,1,2]\n",
    "# label['Pedestrians'] = [0,1,2,3]\n",
    "# # scenic_script_path = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "# # scenario = scenic.scenarioFromFile(scenic_script_path)\n",
    "# l = generateObjectMatchingCorrespondenceSet(scenario, label)\n",
    "# print(len(l))\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Object Matching\n",
    "import math\n",
    "from scenic.domains.driving.roads import Network\n",
    "import random\n",
    "\n",
    "def conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    for obj_index in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[obj_index]\n",
    "        for attribute_name in attributeList:\n",
    "            objType = findObjType(obj)\n",
    "            attr_label = extractLabelAttribute(label, obj_index, attribute_name, objType, \\\n",
    "                                               dataType, correspondence, egoObjIndex)\n",
    "            if isinstance(attr_label, (float, int)):\n",
    "                attr_label = Constant(attr_label)\n",
    "            obj_attr = getattr(obj, attribute_name)\n",
    "            obj_attr.conditionTo(attr_label)\n",
    "\n",
    "def satisfyHardConstraints(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    unconditionAllAttributes(scenario)\n",
    "    conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType)\n",
    "    return scenario.checkRequirements()\n",
    "\n",
    "def scenarioObjClassCount(scenario):\n",
    "    # check whether the number of objects match per class\n",
    "    objClassCountDict = {}\n",
    "    for obj in scenario.original_objects:\n",
    "        objType = findObjType(obj)\n",
    "        if obj is not scenario.egoObject:\n",
    "            if objType not in objClassCountDict.keys():\n",
    "                objClassCountDict[objType] = {}\n",
    "                objClassCountDict[objType]['count'] = 1\n",
    "            else:\n",
    "                objClassCountDict[objType]['count'] += 1\n",
    "        else:\n",
    "            objClassCountDict['EgoCar'] = {}\n",
    "            objClassCountDict['EgoCar']['count'] = 1\n",
    "    return objClassCountDict\n",
    "\n",
    "def checkLabelValidity(label, objClassCountDict):\n",
    "    for objType in objClassCountDict.keys():\n",
    "        if objType == 'EgoCar':\n",
    "            continue\n",
    "        if len(label[objType]) < objClassCountDict[objType]['count']:\n",
    "            print(\"INVALID LABEL -- scenario vs label objects mismatch\")\n",
    "            print(\"Issue object type: \", objType)\n",
    "            print(\"len(label[objType]): \", len(label[objType]))\n",
    "            print(\"scenaro objectType's obj number: \", objClassCountDict[objType]['count'])\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def queryLabelSetup(scenario, smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'],\\\n",
    "                   dataType='carla', monolithic_translation=False):\n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # setup basic info\n",
    "    cached_variables = {}\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    cached_variables['variables'] = []\n",
    "    network = Network.fromFile('/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town01.xodr', {})\n",
    "    egoObjIndex = findEgoObjIndex(scenario)\n",
    "    objClassCountDict = scenarioObjClassCount(scenario)\n",
    "    \n",
    "    # Sort Attribute Dependency \n",
    "    dictionary = dependencyAnalysis(scenario, attributeList)\n",
    "    sortedDependencyList = sortDependency(dictionary, scenario, monolithic_translation)\n",
    "    \n",
    "    outputDict = {}\n",
    "    outputDict['cached_variables'] = cached_variables\n",
    "    outputDict['sortedDependencyList'] = sortedDependencyList\n",
    "    outputDict['egoObjIndex'] = egoObjIndex\n",
    "    outputDict['dictionary'] = dictionary\n",
    "    outputDict['objClassCountDict'] = objClassCountDict\n",
    "    outputDict['attributeList'] = attributeList\n",
    "    return outputDict\n",
    "\n",
    "def egoObjInList(jointlyDependentAttributeList, egoObjIndex):\n",
    "    for attr in jointlyDependentAttributeList:\n",
    "        if str(egoObjIndex) in attr:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def parseAttribute(attribute):\n",
    "    obj = attribute.split(\"_\")[0]\n",
    "    obj_num_str = obj.split(\"obj\")[1]\n",
    "    return obj_num_str\n",
    "\n",
    "def addToCheckedObjs(jointlyDependentAttributeList, checkedObjs_str, correspondence):\n",
    "    \n",
    "    for attribute in jointlyDependentAttributeList:\n",
    "        obj_num_str = parseAttribute(attribute)\n",
    "        # map the object number to the actual object in the correspondence\n",
    "#         print(\"addToCheckObjs attribute: \", attribute)\n",
    "#         print(\"addToCheckObjs obj_num_str: \", obj_num_str)\n",
    "        \n",
    "        if obj_num_str != '0':\n",
    "            index = int(obj_num_str)\n",
    "            obj_num_str = str(correspondence[index-1]) # since ego is 0 by default\n",
    "\n",
    "            if obj_num_str not in checkedObjs_str:\n",
    "                checkedObjs_str = checkedObjs_str + obj_num_str\n",
    "                \n",
    "    return checkedObjs_str\n",
    "    \n",
    "def convertToString(correspondence):\n",
    "    output_str = ''\n",
    "    for elem in correspondence:\n",
    "        output_str = output_str + str(elem)\n",
    "    return output_str\n",
    "\n",
    "def isValidCorrespondence(correspondence, invalid_correspondence_list):\n",
    "    correspondence_str = convertToString(correspondence)\n",
    "    \n",
    "    for elem in invalid_correspondence_list:\n",
    "        if correspondence_str.startswith(elem):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def queryLabel(scenario, label, outputDict, errorBound, ego_visibleDistance = 30, ego_viewAngle = 135,\\\n",
    "               dataType='carla', smt_file_path='./test_smt_encoding.smt2', \\\n",
    "               debug=False, monolithic_translation = False, scenic_testing=False):\n",
    "    \n",
    "    objClassCountDict = outputDict['objClassCountDict']\n",
    "#     print(\"objClassCountDict: \", objClassCountDict)\n",
    "    if not checkLabelValidity(label, objClassCountDict):\n",
    "        # number of objects do not match per class ==> reject the label\n",
    "#         print(\"INVALD LABEL! Obj Count does not match\")\n",
    "        return False, False\n",
    "    \n",
    "    # Compute All Correspondence\n",
    "    allObjCorrespondence = generateObjectMatchingCorrespondenceSet(scenario, label)\n",
    "#     print(\"allObjCorrespondence: \", allObjCorrespondence)\n",
    "    \n",
    "    # Unpack variables\n",
    "    cached_variables = outputDict['cached_variables']\n",
    "    sortedDependencyList = outputDict['sortedDependencyList']\n",
    "    egoObjIndex = outputDict['egoObjIndex']\n",
    "#     print(\"egoObjIndex: \", egoObjIndex)\n",
    "    dictionary = outputDict['dictionary']\n",
    "    attributeList = outputDict['attributeList']\n",
    "    \n",
    "    # Create Ego visible region\n",
    "    (ego_x, ego_y) = label['EgoCar']['position']\n",
    "    label_ego_pos = extractLabelAttribute(label, egoObjIndex, 'position', 'EgoCar', \\\n",
    "                                                  dataType, None, egoObjIndex)\n",
    "#     label_ego_heading = extractLabelAttribute(label, egoObjIndex, 'heading', 'EgoCar', \\\n",
    "#                                                   dataType, None, egoObjIndex)\n",
    "#     regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "#                                     math.radians(ego_viewAngle))\n",
    "    regionAroundEgo = CircularRegion(label_ego_pos, ego_visibleDistance)\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    \n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # invalid correspondence list\n",
    "    invalid_correspondence_list = []\n",
    "    num_skipped_samples = 0\n",
    "    \n",
    "#     print(\"begin query\")\n",
    "    for correspondence in allObjCorrespondence:\n",
    "#         print(\"correspondence: \", correspondence)\n",
    "        if isValidCorrespondence(correspondence, invalid_correspondence_list):\n",
    "#             print(\"correspondence is INVALID!\")\n",
    "#             print(\"invalid_correspondence_list: \", invalid_correspondence_list)\n",
    "            num_skipped_samples += 1\n",
    "            continue\n",
    "        \n",
    "        failed, egoInList = False, False\n",
    "#         print(\"queryLabel correspondence: \", correspondence)\n",
    "        checkedObjs_str = ''\n",
    "    \n",
    "        for jointlyDependentAttributeList in sortedDependencyList:\n",
    "            checkedObjs_str = addToCheckedObjs(jointlyDependentAttributeList, checkedObjs_str, correspondence)\n",
    "            \n",
    "            egoInList = egoObjInList(jointlyDependentAttributeList, egoObjIndex)\n",
    "            # Initialize smt file, if exists\n",
    "            initializeSMTFile(smt_file_path)\n",
    "#             print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "            if validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                                            correspondence, egoObjIndex, dataType, errorBound, debug=debug, \\\n",
    "                                            monolithic_translation=monolithic_translation):\n",
    "#                 print(\".........................VALID ATTRIBUTE(S): \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "                conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, \\\n",
    "                                    correspondence, egoObjIndex, label)\n",
    "                resetDictionary(cached_variables, smt_file_path)\n",
    "                \n",
    "            else: # condition attributes in jointlyDependentAttributeList\n",
    "#                 print(\"INVALD LABEL -- NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "                failed = True\n",
    "                unconditionAllAttributes(scenario)\n",
    "                resetDictionary(cached_variables, smt_file_path)\n",
    "                \n",
    "                # save this checkedObjs_str:\n",
    "                if checkedObjs_str not in invalid_correspondence_list:\n",
    "                    invalid_correspondence_list.append(checkedObjs_str)\n",
    "                \n",
    "                if egoInList:\n",
    "#                     print(\"ego object was in the list\")\n",
    "                    return True, False\n",
    "                break\n",
    "        \n",
    "        ## Check Hard Constraint Satisfaction\n",
    "        hardConstraintValid = satisfyHardConstraints(scenario, dictionary, label, attributeList, \\\n",
    "                                                 correspondence, egoObjIndex, dataType)\n",
    "        \n",
    "        if failed and scenic_testing:\n",
    "            return True, False\n",
    "        \n",
    "        if not failed and hardConstraintValid:\n",
    "#             print(\"HARD CONSTRAINT SATISFIED\")\n",
    "#             print(\"valid correspondence: \", correspondence)\n",
    "            print(\"# OF SKIPPED SAMPLES: \", num_skipped_samples)\n",
    "            return True, True\n",
    "        else:\n",
    "            if not failed and not hardConstraintValid:\n",
    "                pass\n",
    "#                 print(\"INVALID LABELS -- HARD CONSTRAINT NOT SATISFIED\")\n",
    "            if scenic_testing:\n",
    "                # the first correspondence is valid\n",
    "                return True, False\n",
    "            failed = False\n",
    "            unconditionAllAttributes(scenario)\n",
    "            resetDictionary(cached_variables, smt_file_path)\n",
    "\n",
    "    return True, False\n",
    "\n",
    "    \n",
    "# def queryLabel(scenario, label, outputDict, errorBound, ego_visibleDistance = 30, ego_viewAngle = 135,\\\n",
    "#                dataType='carla', smt_file_path='./test_smt_encoding.smt2', \\\n",
    "#                debug=False, monolithic_translation = False, scenic_testing=False):\n",
    "    \n",
    "#     objClassCountDict = outputDict['objClassCountDict']\n",
    "# #     print(\"objClassCountDict: \", objClassCountDict)\n",
    "#     if not checkLabelValidity(label, objClassCountDict):\n",
    "#         # number of objects do not match per class ==> reject the label\n",
    "# #         print(\"INVALD LABEL! Obj Count does not match\")\n",
    "#         return False, False\n",
    "    \n",
    "#     # Compute All Correspondence\n",
    "#     allObjCorrespondence = generateObjectMatchingCorrespondenceSet(scenario, label)\n",
    "# #     print(\"allObjCorrespondence: \", allObjCorrespondence)\n",
    "    \n",
    "#     # Unpack variables\n",
    "#     cached_variables = outputDict['cached_variables']\n",
    "#     sortedDependencyList = outputDict['sortedDependencyList']\n",
    "#     egoObjIndex = outputDict['egoObjIndex']\n",
    "#     print(\"egoObjIndex: \", egoObjIndex)\n",
    "#     dictionary = outputDict['dictionary']\n",
    "#     attributeList = outputDict['attributeList']\n",
    "    \n",
    "#     # Create Ego visible region\n",
    "#     (ego_x, ego_y) = label['EgoCar']['position']\n",
    "#     label_ego_pos = extractLabelAttribute(label, egoObjIndex, 'position', 'EgoCar', \\\n",
    "#                                                   dataType, None, egoObjIndex)\n",
    "# #     label_ego_heading = extractLabelAttribute(label, egoObjIndex, 'heading', 'EgoCar', \\\n",
    "# #                                                   dataType, None, egoObjIndex)\n",
    "# #     regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "# #                                     math.radians(ego_viewAngle))\n",
    "#     regionAroundEgo = CircularRegion(label_ego_pos, ego_visibleDistance)\n",
    "#     cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "#     cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    \n",
    "#     # Uncondition previously conditioned dependency objects\n",
    "#     unconditionAllAttributes(scenario)\n",
    "    \n",
    "#     # invalid correspondence list\n",
    "#     invalid_correspondence_list = []\n",
    "    \n",
    "# #     print(\"begin query\")\n",
    "#     for correspondence in allObjCorrespondence:\n",
    "#         failed, egoInList = False, False\n",
    "# #         print(\"queryLabel correspondence: \", correspondence)\n",
    "#         for jointlyDependentAttributeList in sortedDependencyList:\n",
    "#             egoInList = egoObjInList(jointlyDependentAttributeList, egoObjIndex)\n",
    "#             # Initialize smt file, if exists\n",
    "#             initializeSMTFile(smt_file_path)\n",
    "#             print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "#             if validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "#                                             correspondence, egoObjIndex, dataType, errorBound, debug=debug, \\\n",
    "#                                             monolithic_translation=monolithic_translation):\n",
    "# #                 print(\".........................VALID ATTRIBUTE(S): \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "#                 conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, \\\n",
    "#                                     correspondence, egoObjIndex, label)\n",
    "#                 resetDictionary(cached_variables, smt_file_path)\n",
    "#             else: # condition attributes in jointlyDependentAttributeList\n",
    "#                 print(\"INVALD LABEL -- NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "#                 failed = True\n",
    "#                 unconditionAllAttributes(scenario)\n",
    "#                 resetDictionary(cached_variables, smt_file_path)\n",
    "#                 if egoInList:\n",
    "# #                     print(\"ego object was in the list\")\n",
    "#                     return True, False\n",
    "#                 break\n",
    "        \n",
    "#         ## Check Hard Constraint Satisfaction\n",
    "#         hardConstraintValid = satisfyHardConstraints(scenario, dictionary, label, attributeList, \\\n",
    "#                                                  correspondence, egoObjIndex, dataType)\n",
    "        \n",
    "#         if failed and scenic_testing:\n",
    "#             return True, False\n",
    "        \n",
    "#         if not failed and hardConstraintValid:\n",
    "# #             print(\"HARD CONSTRAINT SATISFIED\")\n",
    "# #             print(\"valid correspondence: \", correspondence)\n",
    "#             return True, True\n",
    "#         else:\n",
    "#             if not failed and not hardConstraintValid:\n",
    "#                 pass\n",
    "# #                 print(\"INVALID LABELS -- HARD CONSTRAINT NOT SATISFIED\")\n",
    "#             if scenic_testing:\n",
    "#                 # the first correspondence is valid\n",
    "#                 return True, False\n",
    "#             failed = False\n",
    "#             unconditionAllAttributes(scenario)\n",
    "#             resetDictionary(cached_variables, smt_file_path)\n",
    "\n",
    "#     return True, False\n",
    "\n",
    "def convertScenicLabel(scenic_label, shuffle=False):\n",
    "    label = {}\n",
    "    label['EgoCar'] = {}\n",
    "    ego_pos = scenic_label.egoObject.position\n",
    "    label['EgoCar']['position'] = (ego_pos[0], ego_pos[1])\n",
    "    label['EgoCar']['heading'] = scenic_label.egoObject.heading\n",
    "    label['Vehicles'] = []\n",
    "    label['Pedestrians'] = []\n",
    "    label['Objects'] = []\n",
    "    for obj in scenic_label.objects:\n",
    "        if obj is not scenic_label.egoObject:\n",
    "            objType = findObjType(obj)\n",
    "            objDict = {}\n",
    "            objPos = obj.position\n",
    "            objDict['position'] = (objPos[0], objPos[1])\n",
    "            objDict['heading'] = obj.heading\n",
    "            label[objType].append(objDict)\n",
    "    if shuffle:\n",
    "        random.shuffle(label['Vehicles'])\n",
    "        random.shuffle(label['Pedestrians'])\n",
    "        random.shuffle(label['Objects'])\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globalParameters.map:  /Users/edwardkim/Desktop/Scenic_Query/Scenic/examples/carla/scalability/../../../tests/formats/opendrive/maps/CARLA/Town05.xodr\n",
      "globalParameters.map_options:  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/simulators/carla/model.scenic:56: UserWarning: the \"carla\" package is not installed; will not be able to run dynamic simulations\n",
      "  warnings.warn('the \"carla\" package is not installed; '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sortedDependencyList:  [['obj0_position'], ['obj0_heading'], ['obj1_position'], ['obj1_heading'], ['obj2_position'], ['obj2_heading'], ['obj3_position'], ['obj3_heading'], ['obj4_position'], ['obj4_heading'], ['obj5_position'], ['obj5_heading'], ['obj6_position'], ['obj6_heading'], ['obj7_position'], ['obj7_heading'], ['obj8_position'], ['obj8_heading'], ['obj9_position'], ['obj9_heading']]\n",
      ".......... sampling a new scene from the scenic program ..........\n",
      "sampled label:  {'EgoCar': {'position': (207.26, 8.72), 'heading': 0.01167797486102029}, 'Vehicles': [{'position': (207.14500630655186, 18.566610165180492), 'heading': 0.01167797486102029}, {'position': (202.99223055361372, 23.485797490442497), 'heading': 0.01167797486102029}, {'position': (207.08699907385284, 23.53361826815771), 'heading': 0.01167797486102029}, {'position': (207.20377729363946, 13.534203765123948), 'heading': 0.01167797486102029}, {'position': (204.50601853215178, 13.5026979739114), 'heading': 0.01167797486102029}, {'position': (209.63597765078862, 18.59570098835131), 'heading': 0.01167797486102029}, {'position': (204.55318284810951, 18.53634154001386), 'heading': 0.01167797486102029}, {'position': (209.22509414480706, 13.557809725596178), 'heading': 0.01167797486102029}, {'position': (209.12791198734755, 23.557453081356538), 'heading': 0.01167797486102029}], 'Pedestrians': [], 'Objects': []}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'smt_assert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-504bd1b7c80b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mscenic_script\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./examples/carla/scalability/scalability1.scenic\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mscenario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscenic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenarioFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenic_script\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m valid, generatedScenicLabels, time_measurements = runExperiment(scenario, numTest=100, monolithic_translation=False, \n\u001b[0m\u001b[1;32m     55\u001b[0m                                                                 shuffle=True, debug=False)\n\u001b[1;32m     56\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_measurements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_measurements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-504bd1b7c80b>\u001b[0m in \u001b[0;36mrunExperiment\u001b[0;34m(scenario, numTest, monolithic_translation, shuffle, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         objCountMatched, valid = queryLabel(scenario, label, outputDict, errorBound, dataType='carla', debug=debug, \\\n\u001b[0m\u001b[1;32m     31\u001b[0m                           monolithic_translation=monolithic_translation, scenic_testing=scenic_testing)\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-3f9e923102e1>\u001b[0m in \u001b[0;36mqueryLabel\u001b[0;34m(scenario, label, outputDict, errorBound, ego_visibleDistance, ego_viewAngle, dataType, smt_file_path, debug, monolithic_translation, scenic_testing)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0minitializeSMTFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmt_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m#             print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             if validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n\u001b[0m\u001b[1;32m    182\u001b[0m                                             \u001b[0mcorrespondence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0megoObjIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorBound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                             monolithic_translation=monolithic_translation):\n",
      "\u001b[0;32m<ipython-input-5-0629d6222bec>\u001b[0m in \u001b[0;36mvalidateLabelElement\u001b[0;34m(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, correspondence, egoObjIndex, dataType, errorBound, debug, falseTesting, monolithic_translation)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;31m#         print(\"correspondence: \", correspondence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mattr_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'self'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         translated = translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n\u001b[0m\u001b[1;32m    184\u001b[0m                                           dictionary, errorBound, debug)\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0629d6222bec>\u001b[0m in \u001b[0;36mtranslateAttributeExpressionTree\u001b[0;34m(attribute_name, attr_obj, attr_label, cached_variables, dictionary, errorBound, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0my_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmt_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cond1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mwriteSMTtoFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmt_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmt_assert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmt_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mheading_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smt_assert' is not defined"
     ]
    }
   ],
   "source": [
    "import scenic\n",
    "import time\n",
    "\n",
    "def runExperiment(scenario, numTest, monolithic_translation=False, shuffle=False, debug=False):\n",
    "    outputDict = queryLabelSetup(scenario,  smt_file_path='./test_smt_encoding.smt2', \\\n",
    "                                 attributeList = ['position', 'heading'],dataType = 'carla',\\\n",
    "                                 monolithic_translation=monolithic_translation)\n",
    "    errorBound = {}\n",
    "    errorBound['x'] = 0 # meters == radius of the error margin ball around x\n",
    "    errorBound['y'] = 0 # meters == radius of the error margin ball around y\n",
    "    errorBound['heading'] = 0 # radians = 10 degrees\n",
    "    print(\"sortedDependencyList: \", outputDict['sortedDependencyList'])\n",
    "    \n",
    "    generatedScenicLabels = []\n",
    "    time_measurements = []\n",
    "    \n",
    "    count = 0\n",
    "    num_valid = 0\n",
    "    for i in range(numTest):\n",
    "        count += 1\n",
    "        unconditionAllAttributes(scenario)\n",
    "        print(\".......... sampling a new scene from the scenic program ..........\")\n",
    "        scenic_label, _ = scenario.generateForQuery(maxIterations=50000, verbosity=0)\n",
    "        label = convertScenicLabel(scenic_label, shuffle)\n",
    "        generatedScenicLabels.append(label)\n",
    "        print(\"sampled label: \", label)\n",
    "        scenic_testing = not shuffle\n",
    "        \n",
    "        current_time = time.time()\n",
    "        objCountMatched, valid = queryLabel(scenario, label, outputDict, errorBound, dataType='carla', debug=debug, \\\n",
    "                          monolithic_translation=monolithic_translation, scenic_testing=scenic_testing)\n",
    "        \n",
    "        query_runtime = time.time()-current_time\n",
    "        \n",
    "        if not valid:\n",
    "            print(\"LABEL NOT VALID: \")\n",
    "            print(\"LABEL VALID : \", num_valid)\n",
    "            print(\"# of tried samples: \", count)\n",
    "#             return False, generatedScenicLabels, time_measurements\n",
    "        else:\n",
    "            num_valid += 1 \n",
    "            print(\"# of tried samples: \", count)\n",
    "            print(\"LABEL VALID : \", num_valid)\n",
    "            time_measurements.append(query_runtime)\n",
    "            print(\"query_runtime: \", query_runtime)\n",
    "            \n",
    "            if num_valid >= 10:\n",
    "                break\n",
    "        \n",
    "    return True, generatedScenicLabels, time_measurements\n",
    "\n",
    "scenic_script = \"./examples/carla/scalability/scalability1.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "valid, generatedScenicLabels, time_measurements = runExperiment(scenario, numTest=100, monolithic_translation=False, \n",
    "                                                                shuffle=True, debug=False)\n",
    "avg = sum(time_measurements)/len(time_measurements)\n",
    "var = sum([math.pow(x-avg,2) for x in time_measurements])/(len(time_measurements)-1)\n",
    "std = math.sqrt(var)\n",
    "\n",
    "print(\"time_measurements: \", time_measurements)\n",
    "print(\"average runtime: \", avg)\n",
    "print(\"standard deviation: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum(time_measurements[0:10])/len(time_measurements[0:10])\n",
    "var = sum([math.pow(x-avg,2) for x in time_measurements[0:10]])/(len(time_measurements[0:10])-1)\n",
    "std = math.sqrt(var)\n",
    "\n",
    "print(\"average runtime: \", avg)\n",
    "print(\"standard deviation: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network.fromFile('/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town01.xodr', {})\n",
    "print(network.roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def nuScenesExperiment(scenario, dataset_directory_path):\n",
    "    outputDict = queryLabelSetup(scenario,  smt_file_path='./test_smt_encoding.smt2', \\\n",
    "                                 attributeList = ['position', 'heading'],dataType = 'nuScenes')\n",
    "    errorBound = {}\n",
    "    errorBound['x'] = 0.25 # meters == radius of the error margin ball around x\n",
    "    errorBound['y'] = 0.25 # meters == radius of the error margin ball around y\n",
    "    errorBound['heading'] = 0.0872 # radians = 5 degrees\n",
    "    print(\"sortedDependencyList: \", outputDict['sortedDependencyList'])\n",
    "    \n",
    "    filenames = [file for file in os.listdir(dataset_directory_path) if file.endswith('.jpg')]\n",
    "    numFiles = len(filenames)\n",
    "    count = 0\n",
    "    valid_files = []\n",
    "    invalid_files = []\n",
    "    runtime_dict = {}\n",
    "    runtime_dict['runtime'] = []\n",
    "    runtime_dict['matched_runtime'] = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        count+=1\n",
    "        print(\"# covered imgs: \", count)\n",
    "        img = mpimg.imread(os.path.join(dataset_directory_path, file))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        unconditionAllAttributes(scenario)\n",
    "        label = nusc.get_img_data(file)\n",
    "        print(\"filename: \", file)\n",
    "        print(\"label: \", label)\n",
    "        current_time = time.time()\n",
    "        objCountMatched, valid = queryLabel(scenario, label, outputDict, errorBound, ego_visibleDistance = 50, \\\n",
    "                                              dataType='nuScenes', debug=False)\n",
    "        runtime = time.time()-current_time\n",
    "        if objCountMatched:\n",
    "            runtime_dict['matched_runtime'].append(runtime)\n",
    "        runtime_dict['runtime'].append(runtime)\n",
    "        \n",
    "        if not valid:\n",
    "            print(\"LABEL NOT VALID: \", file)\n",
    "            invalid_files.append(file)\n",
    "        else:\n",
    "            print(\"LABEL VALID: \", file)\n",
    "            valid_files.append(file)\n",
    "    \n",
    "    return valid_files, invalid_files, runtime_dict\n",
    "\n",
    "directory = '/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data/experiment_results'\n",
    "subject1 = 'experiment_result_JayShenoy'\n",
    "subject2 = 'experiment_result_TaeSung'\n",
    "subject3 = 'experiment_result_Xiangyu'\n",
    "scenario_list = ['scenario1','scenario2','scenario3','scenario4','scenario5']\n",
    "dataset_directory_path = os.path.join(directory, 'data')\n",
    "scenic_script_path = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script_path)\n",
    "start_time = time.time()\n",
    "valid_files, invalid_files, runtime_dict = nuScenesExperiment(scenario, dataset_directory_path)\n",
    "print(\"total Query Time: \", time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scenario1_errors = ['n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299229362404.jpg',\n",
    "          'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326412404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299149412404.jpg',\n",
    "          'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659406262404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299240112404.jpg',\n",
    "          'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159662404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299239112404.jpg',\n",
    "          'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153162404.jpg'\n",
    "         ]\n",
    "\n",
    "\n",
    "# dataset_directory_path = os.path.join(directory, 'scenario2_intersection')\n",
    "# filenames = set([file for file in os.listdir(dataset_directory_path) if file.endswith('.jpg')])\n",
    "# valids = set(valid_files)\n",
    "# diff_invalids = valids.difference(filenames)\n",
    "# print(len(diff_invalids))\n",
    "\n",
    "print(len(valid_files))\n",
    "print(len(invalid_files))\n",
    "print(\"avg runtime: \", sum(runtime_dict['runtime'])/len(runtime_dict['runtime']))\n",
    "print(\"avg matched runtime: \", sum(runtime_dict['matched_runtime'])/len(runtime_dict['matched_runtime']))\n",
    "valids = valid_files.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in valid_files:\n",
    "    src_file = os.path.join(dataset_directory_path, file)\n",
    "    dst_dir = os.path.join(directory, 'scenario3_queried')\n",
    "    shutil.copy(src_file, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum(runtime_dict['matched_runtime'])/len(runtime_dict['matched_runtime'])\n",
    "var = sum([math.pow(x-avg,2) for x in runtime_dict['matched_runtime']])/(len(runtime_dict['matched_runtime'])-1)\n",
    "std = math.sqrt(var)\n",
    "print(std)\n",
    "print(sum(runtime_dict['runtime'])/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(runtime_dict['matched_runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scenario.original_objects[1].position\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scenicExperiment(numTest, monolithic_translation=False, shuffle=False, debug = False):\n",
    "    directory = \"./examples/carla/ICCV_Scenic_Experiments\"\n",
    "    timing_dict = {}\n",
    "    for i in range(1,11):\n",
    "        if i!=2:\n",
    "            continue\n",
    "        scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/\"+str(i)+\"_agent_scenario.scenic\"\n",
    "        scenario = scenic.scenarioFromFile(scenic_script)\n",
    "        valid, testedScenicLabels, time_measurements = runExperiment(scenario, numTest, monolithic_translation,\\\n",
    "                                                                    shuffle, debug=debug)\n",
    "        if not valid:\n",
    "            print(\"Invalid Experiment Detected, Stop experiment.....\")\n",
    "            return timing_dict\n",
    "        timing_dict[i] = {}\n",
    "        avg = sum(time_measurements)/len(time_measurements)\n",
    "        var = sum([(t-avg)**2 for t in time_measurements])/len(time_measurements)\n",
    "        timing_dict[i]['runtime']= time_measurements\n",
    "        timing_dict[i]['avg_runtime'] = avg\n",
    "        timing_dict[i]['runtime_variance'] = var\n",
    "        print(\"i: \", i)\n",
    "        print(\"avg: \", avg)\n",
    "        print(\"variance: \", var)\n",
    "        \n",
    "    return timing_dict\n",
    "\n",
    "timing_dict = scenicExperiment(numTest=10, monolithic_translation=False, shuffle=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scenicExperiment(numTest, monolithic_translation=False, shuffle=False):\n",
    "    directory = \"./examples/carla/ICCV_Human_Experiments\"\n",
    "    timing_dict = {}\n",
    "    for i in range(1,6):\n",
    "        scenic_script = os.path.join(directory, \"experiment\"+str(i)+\".scenic\")\n",
    "        scenario = scenic.scenarioFromFile(scenic_script)\n",
    "        valid, testedScenicLabels, time_measurements = runExperiment(scenario, numTest, monolithic_translation,\\\n",
    "                                                                    shuffle)\n",
    "        if not valid:\n",
    "            print(\"Invalid Experiment Detected, Stop experiment.....\")\n",
    "            return timing_dict\n",
    "        timing_dict[i] = {}\n",
    "        avg = sum(time_measurements)/len(time_measurements)\n",
    "        var = sum([(t-avg)**2 for t in time_measurements])/len(time_measurements)\n",
    "        timing_dict[i]['runtime']= time_measurements\n",
    "        timing_dict[i]['avg_runtime'] = avg\n",
    "        timing_dict[i]['runtime_variance'] = var\n",
    "        print(\"i: \", i)\n",
    "        print(\"avg: \", avg)\n",
    "        print(\"variance: \", var)\n",
    "        \n",
    "    return timing_dict\n",
    "\n",
    "timing_dict = scenicExperiment(numTest=10, monolithic_translation=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil\n",
    "scenario1_errors = ['n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299229362404.jpg',\n",
    "          'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326412404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299149412404.jpg',\n",
    "          'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659406262404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299240112404.jpg',\n",
    "          'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159662404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299239112404.jpg',\n",
    "          'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153162404.jpg'\n",
    "         ]\n",
    "directory = '/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data/experiment_results'\n",
    "src_dir = os.path.join(directory, 'scenario2_queried')\n",
    "dst_dir = os.path.join(directory, 'scenario2_intersection')\n",
    "queried_imgs = set([file for file in os.listdir(src_dir) if file.endswith('.jpg')])\n",
    "manual_imgs = set([file for file in os.listdir(dst_dir) if file.endswith('.jpg')])\n",
    "diff = queried_imgs.difference(manual_imgs)\n",
    "for img in diff:\n",
    "    src = os.path.join(src_dir, img)\n",
    "    dst = os.path.join(directory, 'scenario2_missed_scenes_by_humans')\n",
    "    shutil.copy(src, dst)\n",
    "#     if img in scenario1_errors:\n",
    "#         dst = os.path.join(directory, 'scenario1_missed_scenes_by_humans/incorrect')\n",
    "#         shutil.copy(src, dst)\n",
    "#     else:\n",
    "#         dst = os.path.join(directory, 'scenario1_missed_scenes_by_humans/correct')\n",
    "#         shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# # map_path = '/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town05.xodr'\n",
    "\n",
    "# for i in range(1):\n",
    "#     unconditionAllAttributes(scenario)\n",
    "#     sample = scenario.generateForQuery(maxIterations = 4000, verbosity=0)\n",
    "#     label, _ = sample\n",
    "#     if not validateLabel(scenario, label, dataType='nuScenes', debug=False):\n",
    "#         print(\"NOT VALID LABEL\")\n",
    "#         break\n",
    "#     else:\n",
    "#         print(\"label is valid: \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issue1: ahead/behind, left/right of uses the same heading angle as the referenced\n",
    "        (1) As a result, position & heading are jointly dependent\n",
    "        ==> what if we do not allow joint dependency between position and heading?\n",
    "        This assumes that we can decouple joint dependency between the two, if exists.\n",
    "        Is this true? Yes\n",
    "        ==> Limitation: if many there are many jointly dependent features all at once, it may not be feasible to solve\n",
    "        \n",
    "        (2) an obj can have its position be dependent on its heading because its heading is the same as the \n",
    "        heading of another object to which the obj is depedent\n",
    "        ==> is this only an issue with ego? because the ordering of the objects \n",
    "        ==> ==> solution: just keep the original objects ordering\n",
    "\n",
    "Issue2: my assumption that jointly dependent and dependent relationships are disjoint is wrong\n",
    "        (e.g. dependencyAnalysisTest4.scenic)\n",
    "        ==> it's not possible to capture such case since the attribute contains the intermediate variable\n",
    "        ==> another ordering process needs to be done within jointly dependent features based on dependence relations\n",
    "\n",
    "Issue3: Need to check the case when multiple attributes are dependent on another attributes\n",
    "        (e.g. )\n",
    "        \n",
    "\n",
    "Sorting Approach\n",
    "Since the objects are listed in the order the scenario is written, \n",
    "the order in which SMT translation is to be done stays intact\n",
    "The only issue now is to determine joint dependency\n",
    "==> before adding to joint dependency, check whether the jointly dependent attribute is dependent on any of the\n",
    "other jointly dependent attributes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
